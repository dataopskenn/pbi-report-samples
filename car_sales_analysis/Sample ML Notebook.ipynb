{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T15:59:56.770749Z",
     "start_time": "2021-04-14T15:59:55.131947Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use = \"ggplot\"\n",
    "import seaborn as sns\n",
    "plt.rcParams['figure.figsize'] = (10, 7)\n",
    "sns.set(rc={'figure.figsize': (15, 7)})  # For making the seaborn plots the same size\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x) #prevent python from printing exponents\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "\n",
    "from sklearn import pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_log_error, r2_score, roc_auc_score\n",
    "from math import sqrt\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Tables into Python using Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all readings table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location: Datasets\\bodytype.csv\n",
      "File Name: bodytype.csv\n",
      "Content:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>sailthru_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Saloons</td>\n",
       "      <td>Saloon vehicles</td>\n",
       "      <td>saloons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Hatchbacks</td>\n",
       "      <td>Hatchback Vehicles</td>\n",
       "      <td>hatchbacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4 Wheel Drives &amp; SUVs</td>\n",
       "      <td>4 Wheel Drives &amp; SUVs</td>\n",
       "      <td>suvs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Station Wagons</td>\n",
       "      <td>Station Wagons</td>\n",
       "      <td>station wagons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Pickups</td>\n",
       "      <td>Pickups</td>\n",
       "      <td>pickups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>Motorbikes</td>\n",
       "      <td>Motorbikes</td>\n",
       "      <td>motorbikes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>Convertibles</td>\n",
       "      <td>Convertibles</td>\n",
       "      <td>convertibles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>Buses, Taxis and Vans</td>\n",
       "      <td>Buses, Taxis and Vans</td>\n",
       "      <td>vans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>Trucks</td>\n",
       "      <td>Trucks</td>\n",
       "      <td>trucks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>Machinery and Tractors</td>\n",
       "      <td>Machinery and Tractors</td>\n",
       "      <td>tractors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>Trailers</td>\n",
       "      <td>Trailers</td>\n",
       "      <td>trucks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>Minis</td>\n",
       "      <td>Minis</td>\n",
       "      <td>minis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>cars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>Coupes</td>\n",
       "      <td>Coupes</td>\n",
       "      <td>coupes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>Quad Bikes</td>\n",
       "      <td>Quad Bikes</td>\n",
       "      <td>quad-bikes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                   title             description    sailthru_tag\n",
       "0    2                 Saloons         Saloon vehicles         saloons\n",
       "1    3              Hatchbacks      Hatchback Vehicles      hatchbacks\n",
       "2    4   4 Wheel Drives & SUVs   4 Wheel Drives & SUVs            suvs\n",
       "3    5          Station Wagons          Station Wagons  station wagons\n",
       "4    6                 Pickups                 Pickups         pickups\n",
       "5    7              Motorbikes              Motorbikes      motorbikes\n",
       "6    8            Convertibles            Convertibles    convertibles\n",
       "7    9   Buses, Taxis and Vans   Buses, Taxis and Vans            vans\n",
       "8   10                  Trucks                  Trucks          trucks\n",
       "9   11  Machinery and Tractors  Machinery and Tractors        tractors\n",
       "10  12                Trailers                Trailers          trucks\n",
       "11  13                   Minis                   Minis           minis\n",
       "12  14                   Other                   Other            cars\n",
       "13  15                  Coupes                  Coupes          coupes\n",
       "14  16              Quad Bikes              Quad Bikes      quad-bikes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Location: Datasets\\categories.csv\n",
      "File Name: categories.csv\n",
      "Content:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>slug</th>\n",
       "      <th>price_guide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alfa Romeo</td>\n",
       "      <td>alfa-romeo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Aston Martin</td>\n",
       "      <td>aston-martin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Audi</td>\n",
       "      <td>audi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Bentley</td>\n",
       "      <td>bentley</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>BMW</td>\n",
       "      <td>bmw</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15915</th>\n",
       "      <td>16132</td>\n",
       "      <td>VS150</td>\n",
       "      <td>vespa-vs150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15916</th>\n",
       "      <td>16133</td>\n",
       "      <td>208 D</td>\n",
       "      <td>mercedes-benz-208-d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15917</th>\n",
       "      <td>16134</td>\n",
       "      <td>208DA</td>\n",
       "      <td>mercedes-benz-208da</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15918</th>\n",
       "      <td>16135</td>\n",
       "      <td>Truck</td>\n",
       "      <td>jmc-truck</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15919</th>\n",
       "      <td>16136</td>\n",
       "      <td>V250</td>\n",
       "      <td>mercedes-benz-v250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15920 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id         title                 slug  price_guide\n",
       "0          1    Alfa Romeo           alfa-romeo            0\n",
       "1          2  Aston Martin         aston-martin            0\n",
       "2          3          Audi                 audi            0\n",
       "3          4       Bentley              bentley            0\n",
       "4          5           BMW                  bmw            0\n",
       "...      ...           ...                  ...          ...\n",
       "15915  16132         VS150          vespa-vs150            0\n",
       "15916  16133         208 D  mercedes-benz-208-d            0\n",
       "15917  16134         208DA  mercedes-benz-208da            0\n",
       "15918  16135         Truck            jmc-truck            0\n",
       "15919  16136          V250   mercedes-benz-v250            0\n",
       "\n",
       "[15920 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Location: Datasets\\condition.csv\n",
      "File Name: condition.csv\n",
      "Content:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Brand New</td>\n",
       "      <td>Brand New</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Foreign Used</td>\n",
       "      <td>Foreign Used</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Locally Used</td>\n",
       "      <td>Locally Used</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         title   description\n",
       "0   1     Brand New     Brand New\n",
       "1   2  Foreign Used  Foreign Used\n",
       "2   3  Locally Used  Locally Used"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Location: Datasets\\listing.csv\n",
      "File Name: listing.csv\n",
      "Content:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>old_id</th>\n",
       "      <th>title</th>\n",
       "      <th>location_id</th>\n",
       "      <th>listing_status_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>586520</td>\n",
       "      <td>1</td>\n",
       "      <td>Toyota Avalon</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>586521</td>\n",
       "      <td>2</td>\n",
       "      <td>Toyota Camry</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>586522</td>\n",
       "      <td>3</td>\n",
       "      <td>Toyota HiAce</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>586523</td>\n",
       "      <td>4</td>\n",
       "      <td>Honda Accord</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>586524</td>\n",
       "      <td>5</td>\n",
       "      <td>Man ERF</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775194</th>\n",
       "      <td>2234858</td>\n",
       "      <td>0</td>\n",
       "      <td>Toyota RAV4 Limited</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775195</th>\n",
       "      <td>2234859</td>\n",
       "      <td>0</td>\n",
       "      <td>Land Rover Range Rover Sport 4.4 V8</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775196</th>\n",
       "      <td>2234860</td>\n",
       "      <td>0</td>\n",
       "      <td>Toyota Camry SE</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775197</th>\n",
       "      <td>2234861</td>\n",
       "      <td>0</td>\n",
       "      <td>Lexus ES 350</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775198</th>\n",
       "      <td>2234862</td>\n",
       "      <td>0</td>\n",
       "      <td>Lexus RX 350 AWD</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>775199 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  old_id                                title  location_id  \\\n",
       "0        586520       1                        Toyota Avalon            2   \n",
       "1        586521       2                         Toyota Camry            2   \n",
       "2        586522       3                         Toyota HiAce            2   \n",
       "3        586523       4                         Honda Accord            2   \n",
       "4        586524       5                              Man ERF            2   \n",
       "...         ...     ...                                  ...          ...   \n",
       "775194  2234858       0                  Toyota RAV4 Limited            2   \n",
       "775195  2234859       0  Land Rover Range Rover Sport 4.4 V8            2   \n",
       "775196  2234860       0                      Toyota Camry SE            2   \n",
       "775197  2234861       0                         Lexus ES 350            2   \n",
       "775198  2234862       0                     Lexus RX 350 AWD            2   \n",
       "\n",
       "        listing_status_id  \n",
       "0                       2  \n",
       "1                       2  \n",
       "2                       2  \n",
       "3                       2  \n",
       "4                       2  \n",
       "...                   ...  \n",
       "775194                  5  \n",
       "775195                  5  \n",
       "775196                  5  \n",
       "775197                  5  \n",
       "775198                  5  \n",
       "\n",
       "[775199 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Location: Datasets\\trueprices.csv\n",
      "File Name: trueprices.csv\n",
      "Content:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>make_id</th>\n",
       "      <th>model_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>is_verified_dealer</th>\n",
       "      <th>price</th>\n",
       "      <th>year_of_manufacture</th>\n",
       "      <th>domain_id</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>condition_type_id</th>\n",
       "      <th>body_type_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>809</td>\n",
       "      <td>5540</td>\n",
       "      <td>0</td>\n",
       "      <td>400000</td>\n",
       "      <td>1997</td>\n",
       "      <td>6</td>\n",
       "      <td>1596322</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>1706</td>\n",
       "      <td>10782</td>\n",
       "      <td>0</td>\n",
       "      <td>1700000</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>1596328</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13339</td>\n",
       "      <td>13812</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3300000</td>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>1596330</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>1051</td>\n",
       "      <td>15359</td>\n",
       "      <td>0</td>\n",
       "      <td>2300000</td>\n",
       "      <td>2003</td>\n",
       "      <td>6</td>\n",
       "      <td>1596332</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>57</td>\n",
       "      <td>1698</td>\n",
       "      <td>10714</td>\n",
       "      <td>0</td>\n",
       "      <td>3700000</td>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>1596337</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195260</th>\n",
       "      <td>628346</td>\n",
       "      <td>29</td>\n",
       "      <td>13743</td>\n",
       "      <td>14321</td>\n",
       "      <td>1</td>\n",
       "      <td>22000000</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>2234706</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195261</th>\n",
       "      <td>628347</td>\n",
       "      <td>35</td>\n",
       "      <td>1184</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6200000</td>\n",
       "      <td>2011</td>\n",
       "      <td>6</td>\n",
       "      <td>2234758</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195262</th>\n",
       "      <td>628348</td>\n",
       "      <td>38</td>\n",
       "      <td>1242</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3800000</td>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>2234764</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195263</th>\n",
       "      <td>628349</td>\n",
       "      <td>19</td>\n",
       "      <td>817</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3800000</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>2234765</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195264</th>\n",
       "      <td>628350</td>\n",
       "      <td>57</td>\n",
       "      <td>1693</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5000000</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>2234773</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195265 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  make_id  model_id  series_id  is_verified_dealer     price  \\\n",
       "0            1       19       809       5540                   0    400000   \n",
       "1            2       57      1706      10782                   0   1700000   \n",
       "2            3    13339     13812          0                   1   3300000   \n",
       "3            4       30      1051      15359                   0   2300000   \n",
       "4            6       57      1698      10714                   0   3700000   \n",
       "...        ...      ...       ...        ...                 ...       ...   \n",
       "195260  628346       29     13743      14321                   1  22000000   \n",
       "195261  628347       35      1184          0                   1   6200000   \n",
       "195262  628348       38      1242          0                   1   3800000   \n",
       "195263  628349       19       817          0                   1   3800000   \n",
       "195264  628350       57      1693          0                   0   5000000   \n",
       "\n",
       "        year_of_manufacture  domain_id  listing_id  condition_type_id  \\\n",
       "0                      1997          6     1596322                  3   \n",
       "1                      2009          6     1596328                  3   \n",
       "2                      2010          6     1596330                  3   \n",
       "3                      2003          6     1596332                  2   \n",
       "4                      2008          6     1596337                  2   \n",
       "...                     ...        ...         ...                ...   \n",
       "195260                 2014          6     2234706                  2   \n",
       "195261                 2011          6     2234758                  2   \n",
       "195262                 2008          6     2234764                  3   \n",
       "195263                 2014          6     2234765                  3   \n",
       "195264                 2012          6     2234773                  3   \n",
       "\n",
       "        body_type_id  \n",
       "0                  2  \n",
       "1                  2  \n",
       "2                  2  \n",
       "3                  2  \n",
       "4                  2  \n",
       "...              ...  \n",
       "195260             4  \n",
       "195261             2  \n",
       "195262             4  \n",
       "195263             4  \n",
       "195264             2  \n",
       "\n",
       "[195265 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = r'Datasets' # csv files location on my PC\n",
    "csv_files = glob.glob(path + \"/*.csv\")\n",
    "all_files = []\n",
    "\n",
    "# loop over the list of csv files\n",
    "for file in csv_files:\n",
    "      \n",
    "    # read the csv file\n",
    "    df = pd.read_csv(file, header = 0, delimiter=\";\", decimal = \",\", index_col=False)\n",
    "    all_files.append(df) # saving all the file names in a list\n",
    "      \n",
    "    # print the location and filename\n",
    "    print('Location:', file)\n",
    "    print('File Name:', file.split(\"\\\\\")[-1])\n",
    "      \n",
    "    # print the content\n",
    "    print('Content:')\n",
    "    display(df)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Univariate and multivariate analysis to help understand the values of car prices and how some other variables affect it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the files into pandas dataframe using their names\n",
    "trueprices = pd.read_csv(r'Datasets/trueprices.csv', header = 0, delimiter=\";\", decimal = \",\", index_col=False)\n",
    "bodytype = pd.read_csv(r'Datasets/bodytype.csv', header = 0, delimiter=\";\", decimal = \",\", index_col=False)\n",
    "categories = pd.read_csv(r\"Datasets/categories.csv\", header = 0, delimiter=\";\", decimal = \",\", index_col=False)\n",
    "condition = pd.read_csv(r\"Datasets/condition.csv\", header = 0, delimiter=\";\", decimal = \",\", index_col=False)\n",
    "listing = pd.read_csv(r\"Datasets/listing.csv\", header = 0, delimiter=\";\", decimal = \",\", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name is the dataset file is: bodytype.csv\n",
      "The name is the dataset file is: categories.csv\n",
      "The name is the dataset file is: condition.csv\n",
      "The name is the dataset file is: listing.csv\n",
      "The name is the dataset file is: trueprices.csv\n",
      "The corresponding/respective shapes/sizes of the datasets are: (15, 4)\n",
      "The corresponding/respective shapes/sizes of the datasets are: (15920, 4)\n",
      "The corresponding/respective shapes/sizes of the datasets are: (3, 3)\n",
      "The corresponding/respective shapes/sizes of the datasets are: (775199, 5)\n",
      "The corresponding/respective shapes/sizes of the datasets are: (195265, 11)\n"
     ]
    }
   ],
   "source": [
    "for file in csv_files:\n",
    "    print(\"The name is the dataset file is: {}\" .format(file.split(\"\\\\\")[-1]))\n",
    "\n",
    "for file in all_files:\n",
    "    print (\"The corresponding/respective shapes/sizes of the datasets are: {}\".format(file.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Analysis for car prices.\n",
    "\n",
    "The challenge is to predict the price of different vehicle models. This variable is usually referred to as the `target` variable in statistical and machine learning models. <br>\n",
    "For this task, this variable is stored in the `price` column of the `trueprice` dataset.<br>\n",
    "\n",
    "First, let us check for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there any missing values in trueprices set\n",
    "ax = trueprices.isna().sum().sort_values().plot(kind = 'barh', figsize = (9, 10))\n",
    "plt.title('Percentage of Missing Values Per Column in trueprices Set', fontdict={'size':15})\n",
    "for p in ax.patches:\n",
    "    percentage ='{:,.0f}%'.format((p.get_width()/trueprices.shape[0])*100)\n",
    "    width, height =p.get_width(),p.get_height()\n",
    "    x=p.get_x()+width+0.02\n",
    "    y=p.get_y()+height/2\n",
    "    ax.annotate(percentage,(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values in this data set. \n",
    "\n",
    "Now, we can use the `series.describe` function to give us the `five summary statistics` for the numerical columns of the dataset. The reason for this is to understand the nature of the data before we merge it with other datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trueprices.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trueprices.price.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The average price of the {} sold cars is about NGN {}\". format(trueprices.price.count(), trueprices.price.mean()))\n",
    "print(\"The high value of standard deviation (std) of {} signifies the relative wide range in car prices\". format(trueprices.price.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between the 50th percentile, the mean and maximum (max) price suggeest that the majority of cars sold fall below NGN 3.3m, as such the price distribution curve will be skewed towards the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (\"Skewness is:\", trueprices.price.skew())\n",
    "#print(\"Kurtosis is:\", trueprices.price.kurt())\n",
    "#plt.hist(trueprices.price, color='blue', bins = 5)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In statistics, a data with both skewness and kurtosis close to zero means that the data is very close to being a normal distribution. Clearly, our data here is not normally distributed given the value of the skewness and kurtosis. The skewness shows where the longer tail of the distribution lies, hence a positive skewness means the longer tail goes towards the right.\n",
    "The kurtosis shows how sharp the tip (relative to a standard bell curve) of the distribution is. The closer to zero it is, the normal our data looks. Hence we need to improve the normality or linearity of our data set.\n",
    "The values of our skewness and kurtosis clearly signifies that our car price distribution is a long way from being normally distributed, hence a need to improve the linearity and distribution of car price distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving the Shape and Linearity of the distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will need to perform a regression analysis on this data set, which has turned out to be right skewed, we need to improve on its linearity, i.e to normalise the data. One way to do this is to log-transform the data. Although, the predictions will also be log-transformed at the end of this analysis, we will have to transform them, back to their original forms at the end.\n",
    "\n",
    "Using the np.log() function to transform the car price data and setting it as our **target variable** for prediction, after which we will now check for the skewness of this transformation using a histogram still;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.log(trueprices.price)\n",
    "print (\"Skew is:\", target.skew())\n",
    "plt.hist(target, color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skewness is:\", target.skew())\n",
    "print(\"Kurtosis is:\", target.kurt())\n",
    "\n",
    "sns.distplot(target, color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using the log transformation function to transform our data, the car price data now close very close to being normally distributed. This can be seen as the values for the skewness and kurtosis are now closer to zero than before.\n",
    "\n",
    "The line plot below compares the initial distribution shape of our data set with that of the transformed (normalised) data set. While the probability plot compares the linearity of our transformation to that of a perfectly linear data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.distplot(target, fit=norm)\n",
    "#fig = plt.figure()\n",
    "#res = stats.probplot(target, plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although, our data still does not look perfectly linear, we have most of the values within our line of best fit, as such this is somethin we can work with to create a predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with numerical features\n",
    "\n",
    "Considering some numeric features, taking a look at them and plotting them on charts for further exploration. The .select.dtypes() method returns a subset of columns matching the specified data types (where num_cols = numeric features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = trueprices.select_dtypes(include=[np.number])\n",
    "num_cols.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trueprices data presently lists all columns as numerical. The contents of some of these columns do not agree with this. Now, we will merge this dataset with other datasets to get the true datatypes of some of the columns in the data which have links with other datasets. To aid this merging we will consider the followiing important things about out datasets, which help us to see how they are linked with the trueprices dataset:\n",
    "\n",
    "- The id column of the bodytype dataset is directly linked to the body_type_id column of the trueprices dataset\n",
    "- The id column of the condition dataset is directly linked to the condition_type_id of the trueprices dataset\n",
    "- The id column of the listing dataset is directly linked to the listing_id column of the trueprices dataset\n",
    "- The id column of the categories dataset is directly linked to the model_id column of the trueprices dataset\n",
    "\n",
    "The relationship between the trueprpices dataset and the other datasets provided will be used to merge them into one big dataset, which we will use for predictive modelling. During the merging, some columns which do not have relevant information, or holds duplicate information with another column will be dropped or not even merged at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dimesions before merging dataframes:\" + str(trueprices.shape))\n",
    "\n",
    "merger1 = trueprices.copy()\n",
    "\n",
    "merger1 = pd.merge(merger1, bodytype[['id', 'sailthru_tag']], left_on='body_type_id', right_on='id', how= \"left\") # merging the dataset\n",
    "merger1 = merger1.drop(['id_y'], axis=1) # removing column avoid duplicating column names\n",
    "\n",
    "merger2 = pd.merge(merger1, categories[['id', 'slug']], left_on='model_id', right_on='id', how= \"left\") # merging the dataset\n",
    "merger2 = merger2.drop(['id'], axis=1) # removing column avoid duplicating column names\n",
    "\n",
    "merger3 = pd.merge(merger2, condition[['id', 'description']], left_on='condition_type_id', right_on='id', how= \"left\") # merging the dataset\n",
    "merger3 = merger3.drop(['id'], axis=1) # removing column avoid duplicating column names\n",
    "\n",
    "all_data = pd.merge(merger3, listing[['id', 'title', 'location_id', 'listing_status_id']], left_on='listing_id', right_on='id', how= \"left\") # merging the dataset\n",
    "all_data = all_data.drop(['id'], axis=1) # removing column avoid duplicating column names\n",
    "#all_data = all_data.rename(columns={'id_x': 'listing_id'}) # renaming original id column to original name\n",
    "\n",
    "all_data = all_data.rename(columns={'id_x': 'id'}) # renaming original id column to original name\n",
    "\n",
    "print(\"Dimesions after merging dataframes:\" + str(all_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for duplicates again\n",
    "all_data.id.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there any missing values in all_data set\n",
    "ax = all_data.isna().sum().sort_values().plot(kind = 'barh', figsize = (9, 10))\n",
    "plt.title('Percentage of Missing Values Per Column in all_data Set', fontdict={'size':15})\n",
    "for p in ax.patches:\n",
    "    percentage ='{:,.0f}%'.format((p.get_width()/all_data.shape[0])*100)\n",
    "    width, height =p.get_width(),p.get_height()\n",
    "    x=p.get_x()+width+0.02\n",
    "    y=p.get_y()+height/2\n",
    "    ax.annotate(percentage,(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some cars which have been sold, as described by our initial trueprices dataset do not have information about `listing_status_id`, `listing_title` and `loocation_id`. All three variables which are from the listing dataset have been found after merging all the datasets together. This has to be double checked and data quality needs to be improved to avoid this situations like this.\n",
    "\n",
    "It should also be noted that some id columns such as `body_type_id`, `condition_type_id`, `listing_id` and `make_id` now have their categorical components merged with the data in the form of text/object variables and as such will be dropped at some point during this feature engineering process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in all_data.columns:\n",
    "    duplicate_count = all_data.columns.duplicated().sum()\n",
    "    print(\"There are {} duplicated values in the {} column\" .format(duplicate_count, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data for machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting variable types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columns, such as `locatio_id` and `listing_status_id` which in the least, should be integer type columns are being displayed as float types. First we will adjust this. These columns actually have the features of categorical data, as such their missing values will be filled with the `modal` class of the column. After filling the missing values, we will then convert them to categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "missing_cols = all_data[['location_id', 'listing_status_id', 'title']]\n",
    "\n",
    "for col in missing_cols:\n",
    "    all_data[col].fillna(all_data[col].mode(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_data.domain_id.unique(), all_data.body_type_id.unique(), all_data.is_verified_dealer.unique(), all_data.condition_type_id.unique(), all_data.description.unique(), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all datasets into new csv files\n",
    "trueprices.to_csv('Trueprices.csv')\n",
    "condition.to_csv(\"Condtion.csv\")\n",
    "bodytype.to_csv(\"Bodytype.csv\")\n",
    "listing.to_csv(\"Listing.csv\")\n",
    "categories.to_csv('Categories.csv')\n",
    "all_data.to_csv('Merged Data Python.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and test data (train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl = LabelEncoder()\n",
    "all_data['description'] = lbl.fit_transform(all_data['description'].astype(str))\n",
    "all_data['sailthru_tag'] = lbl.fit_transform(all_data['sailthru_tag'].astype(str))\n",
    "all_data['slug'] = lbl.fit_transform(all_data['slug'].astype(str))\n",
    "all_data['title'] = lbl.fit_transform(all_data['title'].astype(str))\n",
    "all_data['location_id'] = lbl.fit_transform(all_data['location_id'].astype('category'))\n",
    "new_all_data = all_data.copy()\n",
    "new_all_data.drop(['id', 'price'], axis=1)\n",
    "new_all_data.columns = lbl.fit_transform(all_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select main columns to be used in training\n",
    "main_cols = all_data.columns.difference(['id', 'price'])\n",
    "data = all_data[main_cols]\n",
    "\n",
    "#split data randomly\n",
    "train = new_all_data.iloc[:150000,:] # transformed train data\n",
    "dftrain = all_data.iloc[:150000,:] # copy of the untransformed train data\n",
    "test = new_all_data.iloc[150001:,:] # transformed test data\n",
    "dftest = all_data.iloc[150001:,:] # copy of the untransformed test data\n",
    "\n",
    "# Select X and y for training and testing\n",
    "X = train\n",
    "X = pd.get_dummies(X)\n",
    "y = np.log(dftrain.price)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=23)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin ML Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg = xgb.XGBRegressor(seed=42, learning_rate = 0.08, max_depth = 4, n_estimators = 1000,\n",
    "                      colsample_bylevel = 1, colsample_bytree = 1, nthread=8, scale_pos_weight=15, min_child_weight=10)\n",
    "xg_hist = xg.fit(X_train, y_train, verbose= True, early_stopping_rounds=10, eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the model against the held out data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_scores = model_selection.cross_val_score(xg_hist, X_train, y_train, cv=5, scoring='neg_mean_squared_error', verbose=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(-1 * xg_scores)\n",
    "print(-1 * xg_scores.mean())\n",
    "print(sqrt(-1 * xg_scores.mean()))\n",
    "print(xg_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on the test set\n",
    "xg_predict = xg_hist.predict(X_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, xg_predict))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, xg_predict))\n",
    "print('Root Mean Squared Error:', sqrt(mean_squared_error(y_test,  xg_predict)))\n",
    "#print('Mean Squared Log Error:',mean_squared_log_error(y_test, xg_predict))\n",
    "print('R-Squared Score: {} %'.format(r2_score(y_test, xg_predict)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict, cross_validate\n",
    "test_pred = xg_hist.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test, test_pred, edgecolors=(0,0,0))\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
    "ax.set_xlabel(\"True\")\n",
    "ax.set_ylabel(\"Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Predictions for the test/untrained data and save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make predictions in test set and prepare submission file\n",
    "predictions = xg_hist.predict(test) # generate predictions for the test/untrained data\n",
    "feats = dftest.select_dtypes(include=[np.number]).interpolate()\n",
    "final_predictions = np.exp(predictions)\n",
    "\n",
    "# create a dataframe to hold new predictions, car_id, and make_model_year\n",
    "xgsubmission = pd.DataFrame()\n",
    "xgsubmission['car_id'] = dftest.id # appending the car_id column from the copied test data\n",
    "xgsubmission['make_model_year'] = dftest.year_of_manufacture # appending the year of manufacture from the copied test data\n",
    "xgsubmission['predicted_price'] = (final_predictions/10000).astype(np.int64)*10000 # round predicted prices to the nearest NGN10,000 and append to the new dataframe\n",
    "xgsubmission.to_csv('Autocheck Predicted Car Prices.csv', index = False) # save dataframe as a csv data file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the predicted price with the actual price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgsubmission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest.price.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(dftest.price, final_predictions, edgecolors=(0,0,0))\n",
    "ax.plot([dftest.price.min(), dftest.price.max()], [dftest.price.min(), dftest.price.max()], 'k--', lw=4)\n",
    "ax.set_xlabel(\"True\")\n",
    "ax.set_ylabel(\"Predicted\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f77312eb24f1b5fc0b6ced5d75009e3262993ab1a86052b4b27f247ff9a59751"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
